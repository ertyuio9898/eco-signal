# --- server.py (ìµœì¢… ì™„ì„± ë²„ì „: ë¡œì»¬/Vercel ëª¨ë‘ ì§€ì›, ëª¨ë“  í•¨ìˆ˜ í¬í•¨) ---

import os
import sys
import time
import logging
import threading
import sqlite3
import configparser
from datetime import datetime
import pytz

from flask import Flask, jsonify, render_template, request
from notion_client import Client
from google.cloud import vision
import database

# --- 1. ì„¤ì • ë¡œë“œ (í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹: ë¡œì»¬ì˜ config.ini ë˜ëŠ” Vercelì˜ í™˜ê²½ ë³€ìˆ˜) ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
config_file_path = 'config.ini'
IS_VERCEL_ENV = os.environ.get('VERCEL') == '1' # Vercelì—ì„œ ìë™ìœ¼ë¡œ ì„¤ì •ë˜ëŠ” í™˜ê²½ ë³€ìˆ˜

try:
    if not IS_VERCEL_ENV and os.path.exists(config_file_path):
        # ë¡œì»¬ í™˜ê²½: config.ini íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ
        logging.info(f"ë¡œì»¬ í™˜ê²½ ê°ì§€. '{config_file_path}'ì—ì„œ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤.")
        config = configparser.ConfigParser()
        config.read(config_file_path, encoding='utf-8')
        
        NOTION_API_KEY = config['SECRETS']['NOTION_API_KEY']
        DATABASE_ID = config['SECRETS']['DATABASE_ID']
        ADMIN_PASSWORD = config['SECRETS']['ADMIN_PASSWORD']
        GOOGLE_CREDENTIALS_FILENAME = config['SECRETS']['GOOGLE_CREDENTIALS_FILENAME']
        IS_TEST_MODE = config['MODE'].getboolean('IS_TEST_MODE')
        
        # ë¡œì»¬ì—ì„œëŠ” êµ¬ê¸€ ì¸ì¦ì„œ íŒŒì¼ ê²½ë¡œë¥¼ ì§ì ‘ í™˜ê²½ ë³€ìˆ˜ì— ì„¤ì •
        # Vercelì—ì„œëŠ” GOOGLE_APPLICATION_CREDENTIALS í™˜ê²½ ë³€ìˆ˜ ìì²´ë¥¼ êµ¬ê¸€ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì§ì ‘ ì‚¬ìš©í•©ë‹ˆë‹¤.
        if getattr(sys, 'frozen', False): application_path = os.path.dirname(sys.executable)
        else: application_path = os.path.dirname(os.path.abspath(__file__))
        credentials_path = os.path.join(application_path, GOOGLE_CREDENTIALS_FILENAME)
        os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credentials_path

    else:
        # Vercel í™˜ê²½: í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì • ë¡œë“œ
        logging.info("Vercel í™˜ê²½ ê°ì§€. í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤.")
        NOTION_API_KEY = os.environ.get('NOTION_API_KEY')
        DATABASE_ID = os.environ.get('DATABASE_ID')
        ADMIN_PASSWORD = os.environ.get('ADMIN_PASSWORD')
        IS_TEST_MODE = os.environ.get('IS_TEST_MODE', 'false').lower() == 'true'
        
    if not all([NOTION_API_KEY, DATABASE_ID, ADMIN_PASSWORD]):
        missing_vars = [var for var in ['NOTION_API_KEY', 'DATABASE_ID', 'ADMIN_PASSWORD'] if not locals().get(var)]
        raise ValueError(f"í•„ìˆ˜ ì„¤ì •ê°’ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_vars)}")

except Exception as e:
    logging.critical(f"ğŸš« ì„¤ì • ë¡œë“œ ì¤‘ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ: {e}")
    sys.exit(1)


# --- 2. ê¸°ë³¸ ì„¤ì • ë° API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
CONFIG = {"check_interval_seconds": 10, "pending_check_interval_seconds": 15, "pending_timeout_seconds": 300, "point_policy": { "tumbler": 20, "cup": 20, "stairs": 30, "paper": 15, "thermos": 25 }, "level_thresholds": { "green": 150, "yellow": 120, "orange": 100 }}
CONFIG["bonus_duration_seconds"] = 60 if IS_TEST_MODE else 3600
if IS_TEST_MODE: logging.warning("### í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. ###")
else: logging.info("### ìš´ì˜ ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤. ###")

try:
    notion = Client(auth=NOTION_API_KEY)
    vision_client = vision.ImageAnnotatorClient()
    logging.info("âœ… ë…¸ì…˜ ë° Google Vision API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ.")
except Exception as e:
    logging.error(f"ğŸš« API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    notion, vision_client = None, None # ì‹¤íŒ¨ ì‹œ í´ë¼ì´ì–¸íŠ¸ Noneìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ê³„ì† ì§„í–‰


# --- 3. ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…ìë“¤ & ì „ì—­ ìƒíƒœ ---
SHARED_STATE = { "signal_level": "orange", "current_points": 100, "last_activity": "ì—†ìŒ", "active_activities": [] }
PENDING_ANALYSIS_QUEUE = {}; PROCESSED_PAGE_IDS = set(); state_lock = threading.Lock()

def analyze_image_and_apply_bonus(page):
    try:
        user_name = page["properties"]["ìƒì„±ì"]["created_by"]["name"]; user_id = database.get_or_create_user(user_name)
        image_url = page["properties"]["íŒŒì¼ê³¼ ë¯¸ë””ì–´"]["files"][0]["file"]["url"]
        logging.info(f"ğŸ‘€ '{user_name}'(ID:{user_id})ë‹˜ì˜ í™œë™ ë¶„ì„ ì‹œì‘: {page['id']}")
        
        # Google Vision API í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
        if vision_client is None:
            logging.error("Google Vision í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ì´ë¯¸ì§€ ë¶„ì„ì„ ê±´ë„ˆëœ€.")
            return

        image = vision.Image(); image.source.image_uri = image_url; response = vision_client.label_detection(image=image)
        detected_tags = [label.description.lower() for label in response.label_annotations]
        applied_bonus = 0; applied_activity = "ê¸°íƒ€ í™œë™"
        for tag, points in CONFIG["point_policy"].items():
            if tag in detected_tags and points > applied_bonus:
                applied_bonus = points; applied_activity = tag
        if applied_bonus > 0:
            with state_lock:
                SHARED_STATE["active_activities"].append({"activity": applied_activity, "points": applied_bonus, "end_time": time.time() + CONFIG["bonus_duration_seconds"]})
            logging.info(f"ğŸ¯ í™œë™ '{applied_activity}' ì¶”ê°€! (+{applied_bonus}ì )")
            database.add_activity_log(user_id, applied_activity, applied_bonus)
            threading.Thread(target=database.check_and_award_achievements, args=(user_id, user_name), daemon=True).start()
    except Exception as e: logging.error(f"ğŸš« AI ë¶„ì„/DB/ë±ƒì§€ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")

# SHARED_STATEë¥¼ ì£¼ê¸°ì ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ëŠ” ìŠ¤ë ˆë“œ (ë¡œì»¬ì—ì„œë§Œ ì‹¤í–‰)
def state_updater_worker():
    logging.info("âš™ï¸ [ìƒíƒœ ì—…ë°ì´íŠ¸ ì§ì›] ê·¼ë¬´ ì‹œì‘.")
    while True:
        try:
            with state_lock:
                SHARED_STATE["active_activities"][:] = [act for act in SHARED_STATE["active_activities"] if act["end_time"] >= time.time()]
                total_points = 100 + sum(act["points"] for act in SHARED_STATE["active_activities"])
                SHARED_STATE["current_points"] = total_points
                SHARED_STATE["last_activity"] = SHARED_STATE["active_activities"][-1]["activity"] if SHARED_STATE["active_activities"] else "ì—†ìŒ"
                level = "orange"
                if total_points >= CONFIG["level_thresholds"]["green"]: level = "green"
                elif total_points >= CONFIG["level_thresholds"]["yellow"]: level = "yellow"
                SHARED_STATE["signal_level"] = level
        except Exception as e: logging.error(f"ğŸš« ìƒíƒœ ì—…ë°ì´íŠ¸ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜: {e}")
        time.sleep(1)

# Notionì„ ì£¼ê¸°ì ìœ¼ë¡œ ê°ì‹œí•˜ëŠ” ìŠ¤ë ˆë“œ (ë¡œì»¬ì—ì„œë§Œ ì‹¤í–‰)
def notion_checker_worker():
    logging.info("âš™ï¸ [ë…¸ì…˜ ê°ì‹œ ì§ì›] ê·¼ë¬´ ì‹œì‘. (Vercelì—ì„œëŠ” ë™ì‘ ì œí•œë¨)")
    try:
        if notion is None:
            logging.error("Notion í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ ë…¸ì…˜ ê°ì‹œ ì‘ì—…ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return # í•¨ìˆ˜ ì¢…ë£Œ
        initial_pages = notion.databases.query(database_id=DATABASE_ID, sorts=[{"property": "ìƒì„± ì¼ì‹œ", "direction": "descending"}], page_size=100).get("results")
        with state_lock:
            for page in initial_pages: PROCESSED_PAGE_IDS.add(page["id"])
        logging.info(f"âœ… ì´ˆê¸° ê¸€ {len(initial_pages)}ê°œ í•™ìŠµ ì™„ë£Œ.")
    except Exception as e: logging.error(f"ğŸš« ì´ˆê¸° ê¸€ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    while True:
        try:
            if notion is None: time.sleep(CONFIG["check_interval_seconds"]); continue
            results = notion.databases.query(database_id=DATABASE_ID, sorts=[{"property": "ìƒì„± ì¼ì‹œ", "direction": "descending"}], page_size=20).get("results")
            with state_lock:
                new_pages = [p for p in results if p["id"] not in PROCESSED_PAGE_IDS and p["id"] not in PENDING_ANALYSIS_QUEUE]
            if new_pages:
                logging.info(f"âœ¨ {len(new_pages)}ê°œì˜ ìƒˆë¡œìš´ ê¸€ ë°œê²¬! ë¶„ì„ ëŒ€ê¸°ì—´ì— ì¶”ê°€í•©ë‹ˆë‹¤.")
                with state_lock:
                    for page in new_pages: PENDING_ANALYSIS_QUEUE[page["id"]] = time.time()
        except Exception as e: logging.error(f"ğŸš« ë…¸ì…˜ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        time.sleep(CONFIG["check_interval_seconds"])

# ë³´ë¥˜ ì¤‘ì¸ ë¶„ì„ íë¥¼ ì²˜ë¦¬í•˜ëŠ” ìŠ¤ë ˆë“œ (ë¡œì»¬ì—ì„œë§Œ ì‹¤í–‰)
def pending_processor_worker():
    logging.info("âš™ï¸ [AI ë¶„ì„ ì „ë¬¸ê°€] ê·¼ë¬´ ì‹œì‘. (Vercelì—ì„œëŠ” ë™ì‘ ì œí•œë¨)")
    while True:
        page_id_to_process = None
        with state_lock:
            if PENDING_ANALYSIS_QUEUE: page_id_to_process = next(iter(PENDING_ANALYSIS_QUEUE))
        if page_id_to_process:
            try:
                if notion is None or vision_client is None:
                    logging.error("Notion ë˜ëŠ” Vision í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•„ AI ë¶„ì„ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    with state_lock: PENDING_ANALYSIS_QUEUE.pop(page_id_to_process, None) # íì—ì„œ ì œê±°í•˜ì—¬ ë¬´í•œ ë£¨í”„ ë°©ì§€
                    time.sleep(CONFIG["pending_check_interval_seconds"]); continue
                    
                page_data = notion.pages.retrieve(page_id=page_id_to_process)
                files_property = page_data["properties"].get("íŒŒì¼ê³¼ ë¯¸ë””ì–´", {}).get("files", [])
                if files_property and files_property[0].get("file"):
                    with state_lock: PENDING_ANALYSIS_QUEUE.pop(page_id_to_process, None); PROCESSED_PAGE_IDS.add(page_id_to_process)
                    threading.Thread(target=analyze_image_and_apply_bonus, args=(page_data,)).start()
                else:
                    with state_lock:
                        if time.time() - PENDING_ANALYSIS_QUEUE.get(page_id_to_process, 0) > CONFIG["pending_timeout_seconds"]:
                            logging.warning(f"âš ï¸ í˜ì´ì§€ '{page_id_to_process}' ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼. ëŒ€ê¸°ì—´ì—ì„œ ì œê±°í•©ë‹ˆë‹¤.")
                            PENDING_ANALYSIS_QUEUE.pop(page_id_to_process, None); PROCESSED_PAGE_IDS.add(page_id_to_process)
            except Exception as e:
                logging.error(f"ğŸš« ëŒ€ê¸°ì—´ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}"); 
                with state_lock: PENDING_ANALYSIS_QUEUE.pop(page_id_to_process, None)
        time.sleep(CONFIG["pending_check_interval_seconds"])

# SHARED_STATEë¥¼ API ìš”ì²­ ì‹œì—ë§Œ ì—…ë°ì´íŠ¸í•˜ëŠ” í•¨ìˆ˜ (Vercelì—ì„œ ì‹¤ì‹œê°„ ë°˜ì˜ì„ ìœ„í•´ ì‚¬ìš©)
def update_shared_state_on_request():
    """API ìš”ì²­ ì‹œ SHARED_STATEë¥¼ ì¦‰ì‹œ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
    with state_lock:
        # ë§Œë£Œëœ í™œë™ ì œê±°
        SHARED_STATE["active_activities"][:] = [act for act in SHARED_STATE["active_activities"] if act["end_time"] >= time.time()]
        
        # í˜„ì¬ ì ìˆ˜ ê³„ì‚°
        total_points = 100 + sum(act["points"] for act in SHARED_STATE["active_activities"])
        SHARED_STATE["current_points"] = total_points
        
        # ë§ˆì§€ë§‰ í™œë™ ì—…ë°ì´íŠ¸ (ê°€ì¥ ìµœê·¼ í™œë™ì´ ì—†ìœ¼ë©´ 'ì—†ìŒ'ìœ¼ë¡œ í‘œì‹œ)
        SHARED_STATE["last_activity"] = SHARED_STATE["active_activities"][-1]["activity"] if SHARED_STATE["active_activities"] else "ì—†ìŒ"
        
        # ì‹ í˜¸ë“± ë ˆë²¨ ì—…ë°ì´íŠ¸
        level = "orange"
        if total_points >= CONFIG["level_thresholds"]["green"]: level = "green"
        elif total_points >= CONFIG["level_thresholds"]["yellow"]: level = "yellow"
        SHARED_STATE["signal_level"] = level


# --- 4. Flask ì•± ì„¤ì • ë° ë¼ìš°íŒ… ---
app = Flask(__name__)

# --- API ì—”ë“œí¬ì¸íŠ¸ ---
@app.route("/status")
def get_status():
    # Vercel í™˜ê²½ì—ì„œëŠ” ìš”ì²­ì´ ì˜¬ ë•Œë§ˆë‹¤ SHARED_STATEë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    # ì´ë ‡ê²Œ í•´ì•¼ ì‹ í˜¸ë“±ê³¼ ì ìˆ˜ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°˜ì˜ë©ë‹ˆë‹¤.
    update_shared_state_on_request()
    with state_lock:
        return jsonify(SHARED_STATE)

@app.route("/ranking")
def get_ranking(): return jsonify(database.get_monthly_ranking())
@app.route("/user/<user_name>/history")
def get_user_history_api(user_name): user_id = database.get_or_create_user(user_name); return jsonify(database.get_user_history(user_id))
@app.route("/user/<user_name>/achievements")
def get_user_achievements_api(user_name): user_id = database.get_or_create_user(user_name); return jsonify(database.get_user_achievements(user_id))
@app.route("/users")
def get_all_users_api(): return jsonify(database.get_all_users())
@app.route("/admin")
def admin_dashboard():
    if request.args.get('password') != ADMIN_PASSWORD: return "<h1>ğŸš« ì ‘ê·¼ì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤.</h1>", 403
    with state_lock: current_status = SHARED_STATE.copy()
    # admin.html í…œí”Œë¦¿ì´ ì—†ìœ¼ë¯€ë¡œ, ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë¡œ ëŒ€ì²´ (ì„ ë°°ë‹˜ì´ ë‚˜ì¤‘ì— admin.html ë§Œë“œì‹œë©´ render_template ì‚¬ìš©)
    return f"Admin Page. Status: {current_status}. DB Path: {database.DB_NAME}"
@app.route("/signal")
def signal_page(): return render_template('signal_web.html')
@app.route("/dashboard")
def dashboard_page(): return render_template('dashboard_web.html')
@app.route("/")
def index_page(): return render_template('index.html')


# --- 5. ì„œë²„ ì‹¤í–‰ ---
# ì´ ë¶€ë¶„ì€ ë¡œì»¬ì—ì„œ 'python server.py'ë¥¼ ì‹¤í–‰í–ˆì„ ë•Œë§Œ ë™ì‘í•©ë‹ˆë‹¤.
# Vercel í™˜ê²½ì—ì„œëŠ” Vercelì´ 'app' ê°ì²´ë¥¼ ì°¾ì•„ì„œ ì§ì ‘ ì‹¤í–‰í•˜ë¯€ë¡œ ì´ ë¸”ë¡ì€ ê±´ë„ˆë›°ì–´ì§‘ë‹ˆë‹¤.
if __name__ == '__main__':
    database.setup_database()
    
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œì—ë§Œ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    if not IS_VERCEL_ENV:
        threading.Thread(target=state_updater_worker, daemon=True, name="StateUpdater").start()
        threading.Thread(target=notion_checker_worker, daemon=True, name="NotionChecker").start()
        threading.Thread(target=pending_processor_worker, daemon=True, name="PendingProcessor").start()
        
    logging.info("ğŸš€ ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì„œë²„ê°€ ì‹œì‘ë©ë‹ˆë‹¤! http://127.0.0.1:5000 ì—ì„œ ì ‘ì†í•˜ì„¸ìš”.")
    app.run(host='0.0.0.0', port=5000, debug=True)